{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from model.layers import GraphSpectralFilterLayer, AnalysisFilter\n",
    "from model.spectral_filter import Graph\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from random import seed as rseed\n",
    "from numpy.random import seed as nseed\n",
    "from webkb import get_dataset, run\n",
    "from webkb.train_eval import evaluate\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9075ef1770>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'Wisconsin'\n",
    "random_splits = False\n",
    "runs = 1\n",
    "epochs =2000\n",
    "alpha = 0.2\n",
    "seed =729\n",
    "lr =0.01\n",
    "weight_decay = 0.0008\n",
    "patience=100\n",
    "hidden=256\n",
    "heads =4\n",
    "dropout=0.3\n",
    "normalize_features =True\n",
    "pre_training = False\n",
    "cuda = False\n",
    "order =16\n",
    "edge_dropout =0\n",
    "node_feature_dropout =0\n",
    "filter_name ='analysis'\n",
    "\n",
    "rseed(seed)\n",
    "nseed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        data = dataset[0]\n",
    "        adj = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.num_edges))\n",
    "        self.G = Graph(adj)\n",
    "        self.G.estimate_lmax()\n",
    "\n",
    "        self.analysis = GraphSpectralFilterLayer(self.G, dataset.num_node_features, hidden,\n",
    "                                                 dropout=dropout, out_channels=heads, filter=filter_name,\n",
    "                                                 pre_training=pre_training, device='cuda' if cuda else 'cpu',\n",
    "                                                 alpha=alpha, order=order)\n",
    "        # self.mlp = nn.Sequential(nn.Linear(hidden * heads, 128),\n",
    "        #                             nn.ReLU(inplace=True),\n",
    "        #                             nn.Linear(128, 64),\n",
    "        #                             nn.ReLU(inplace=True),\n",
    "        #                             nn.Linear(64, 32),\n",
    "        #                             nn.ReLU(inplace=True),\n",
    "        #                             nn.Linear(32, dataset.num_classes),\n",
    "        #                             nn.ReLU(inplace=True))\n",
    "\n",
    "        # self.W = torch.zeros(hidden * heads, dataset.num_classes)\n",
    "\n",
    "        self.synthesis = GraphSpectralFilterLayer(self.G, hidden * heads, dataset.num_classes, filter=filter_name,\n",
    "                                                  device='cuda' if cuda else 'cpu', dropout=dropout,\n",
    "                                                  out_channels=1, alpha=alpha, pre_training=False,\n",
    "                                                  order=order)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.analysis.reset_parameters()\n",
    "        # torch.nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        # for layer in self.mlp:\n",
    "        #     if hasattr(layer, 'reset_parameters'):\n",
    "        #         layer.reset_parameters()\n",
    "        self.synthesis.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, attentions_1 = self.analysis(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, attentions_2 = self.synthesis(x)\n",
    "        x = F.elu(x)\n",
    "        # x = F.elu(x.mm(self.W))\n",
    "        # x = self.mlp(x)\n",
    "        return F.log_softmax(x, dim=1), attentions_1, attentions_2\n",
    "\n",
    "\n",
    "dataset = get_dataset(dataset_name, normalize_features, edge_dropout=edge_dropout,\n",
    "                                node_feature_dropout=node_feature_dropout)\n",
    "\n",
    "if cuda:\n",
    "    dataset[0].to('cuda')\n",
    "\n",
    "# permute_masks = random_planetoid_splits if random_splits else None\n",
    "# run(dataset, Net(dataset), runs, epochs, lr, weight_decay,\n",
    "#     early_stopping, permute_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNet(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(SingleNet, self).__init__()\n",
    "        data = dataset[0]\n",
    "        adj = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.num_edges))\n",
    "        self.G = Graph(adj)\n",
    "        self.G.estimate_lmax()\n",
    "\n",
    "        self.analysis = GraphSpectralFilterLayer(self.G, dataset.num_node_features, hidden,\n",
    "                                                 dropout=dropout, out_channels=heads, filter=filter_name,\n",
    "                                                 pre_training=pre_training, device='cuda' if cuda else 'cpu',\n",
    "                                                 alpha=alpha, order=order)\n",
    "\n",
    "        self.linear = torch.nn.Linear(hidden * heads, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.analysis.reset_parameters()\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, attentions_1 = self.analysis(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.elu(self.linear(x))\n",
    "        return F.log_softmax(x, dim=1), attentions_1, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load trained model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8588235294117647 std: 0.03788595227761946\n"
     ]
    }
   ],
   "source": [
    "model = Net(dataset)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    model = Net(dataset)\n",
    "    model.load_state_dict(torch.load('./model/best_wisconsin_dec_split_{}.pkl'.format(i)))\n",
    "    # model = SingleNet(dataset)\n",
    "    # model.load_state_dict(torch.load('./model/best_cornell_single_dec.pkl'.format(dataset_name)))\n",
    "\n",
    "    eval_info = evaluate(model, dataset[0], split=i)\n",
    "    accs.append(eval_info['test_acc'])\n",
    "\n",
    "accs = torch.tensor(accs)\n",
    "print('acc:', accs.mean().item(), 'std:', accs.std().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtain attention weights in layer 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Build NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_filter_banks(idx=list(range(heads)), kernel=model.analysis.filter._kernel, ax=None, no_ticks=False, legend=True):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    x = torch.linspace(0, 2, 100)\n",
    "    if not ax:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.plot(x, kernel(x).detach()[:, idx])\n",
    "#         if len(idx) > 1 and legend:\n",
    "#             plt.legend(['filter {}'.format(i) for i in range(1, len(idx) + 1)])\n",
    "#         plt.show()\n",
    "    else:\n",
    "        ax.plot(x, kernel(x).detach()[:, idx])\n",
    "#         if len(idx) > 1 and legend:\n",
    "#             ax.legend(['filter {}'.format(i) for i in range(1, len(idx) + 1)])\n",
    "    if no_ticks:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    else:\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Frequency cutoff analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cut frequency bands abruptly\n",
    "class CutOff(nn.Module):\n",
    "    def __init__(self, kernel, min_val = 0, max_val = 2):\n",
    "        super(CutOff, self).__init__()\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.where(\n",
    "            (x.view(-1,1).repeat(1, heads) >= self.min).logical_and(x.view(-1,1).repeat(1, heads) < self.max), \n",
    "            torch.zeros(x.shape[0], heads), self.kernel(x))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluate low pass cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0.0 acc: 0.8588235294117647 std: 0.03788595227761946\n",
      "step: 0.25 acc: 0.8588235294117647 std: 0.03788595227761946\n",
      "step: 0.5 acc: 0.8588235294117647 std: 0.03788595227761946\n",
      "step: 0.75 acc: 0.8588235294117647 std: 0.03788595227761946\n",
      "step: 1.0 acc: 0.6176470588235294 std: 0.06552267207765823\n",
      "step: 1.25 acc: 0.8588235294117647 std: 0.03788595227761946\n",
      "step: 1.5 acc: 0.8607843137254901 std: 0.041799416876652264\n",
      "step: 1.75 acc: 0.8607843137254901 std: 0.041799416876652264\n",
      "[0.8588235294117647, 0.8588235294117647, 0.8588235294117647, 0.8588235294117647, 0.6176470588235294, 0.8588235294117647, 0.8607843137254901, 0.8607843137254901] [0.03788595227761946, 0.03788595227761946, 0.03788595227761946, 0.03788595227761946, 0.06552267207765823, 0.03788595227761946, 0.041799416876652264, 0.041799416876652264]\n"
     ]
    }
   ],
   "source": [
    "step = 0.25\n",
    "acc_mean_by_step = []\n",
    "acc_std_by_step = []\n",
    "\n",
    "for threshold in torch.arange(0, 2, step):\n",
    "    accs = []\n",
    "    for i in range(10):\n",
    "        model = Net(dataset)\n",
    "        model.load_state_dict(torch.load('./model/best_wisconsin_dec_split_{}.pkl'.format(i)))\n",
    "        filter_kernel = model.analysis.filter_kernel\n",
    "    #     syn_filter_kernel = model.synthesis.filter_kernel\n",
    "        model.analysis.filter_kernel = CutOff(min_val=threshold, max_val=threshold+step, kernel=filter_kernel)\n",
    "        model.analysis.filter._kernel = CutOff(min_val=threshold, max_val=threshold+step, kernel=filter_kernel)\n",
    "#         plot_filter_banks(kernel=model.analysis.filter_kernel)\n",
    "        eval_info = evaluate(model, dataset[0], split=i)\n",
    "        accs.append(eval_info['test_acc'])\n",
    "\n",
    "    accs = torch.tensor(accs)\n",
    "    acc_mean_by_step.append(accs.mean().item())\n",
    "    acc_std_by_step.append(accs.std().item())\n",
    "    print('step:', threshold.item(), 'acc:', accs.mean().item(), 'std:', accs.std().item())\n",
    "print(acc_mean_by_step, acc_std_by_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8431372549019607 std: 0.05228758169934639\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    model = SingleNet(dataset)\n",
    "    model.load_state_dict(torch.load('./model/best_wisconsin_single_dec_split_{}.pkl'.format(i)))\n",
    "    # model = SingleNet(dataset)\n",
    "    # model.load_state_dict(torch.load('./model/best_cornell_single_dec.pkl'.format(dataset_name)))\n",
    "\n",
    "    eval_info = evaluate(model, dataset[0], split=i)\n",
    "    accs.append(eval_info['test_acc'])\n",
    "\n",
    "accs = torch.tensor(accs)\n",
    "print('acc:', accs.mean().item(), 'std:', accs.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0.0 acc: 0.8431372549019607 std: 0.05228758169934639\n",
      "step: 0.25 acc: 0.8431372549019607 std: 0.05228758169934639\n",
      "step: 0.5 acc: 0.8431372549019607 std: 0.05228758169934639\n",
      "step: 0.75 acc: 0.8431372549019607 std: 0.05228758169934639\n",
      "step: 1.0 acc: 0.6058823529411764 std: 0.06757676876111285\n",
      "step: 1.25 acc: 0.8431372549019607 std: 0.05228758169934639\n",
      "step: 1.5 acc: 0.8470588235294118 std: 0.04785099403326307\n",
      "step: 1.75 acc: 0.8470588235294118 std: 0.04785099403326307\n",
      "[0.8431372549019607, 0.8431372549019607, 0.8431372549019607, 0.8431372549019607, 0.6058823529411764, 0.8431372549019607, 0.8470588235294118, 0.8470588235294118] [0.05228758169934639, 0.05228758169934639, 0.05228758169934639, 0.05228758169934639, 0.06757676876111285, 0.05228758169934639, 0.04785099403326307, 0.04785099403326307]\n"
     ]
    }
   ],
   "source": [
    "step = 0.25\n",
    "acc_mean_by_step = []\n",
    "acc_std_by_step = []\n",
    "\n",
    "for threshold in torch.arange(0, 2, step):\n",
    "    accs = []\n",
    "    for i in range(10):\n",
    "        model = SingleNet(dataset)\n",
    "        model.load_state_dict(torch.load('./model/best_wisconsin_single_dec_split_{}.pkl'.format(i)))\n",
    "        filter_kernel = model.analysis.filter_kernel\n",
    "    #     syn_filter_kernel = model.synthesis.filter_kernel\n",
    "        model.analysis.filter_kernel = CutOff(min_val=threshold, max_val=threshold+step, kernel=filter_kernel)\n",
    "        model.analysis.filter._kernel = CutOff(min_val=threshold, max_val=threshold+step, kernel=filter_kernel)\n",
    "#         plot_filter_banks(kernel=model.analysis.filter_kernel)\n",
    "        eval_info = evaluate(model, dataset[0], split=i)\n",
    "        accs.append(eval_info['test_acc'])\n",
    "\n",
    "    accs = torch.tensor(accs)\n",
    "    acc_mean_by_step.append(accs.mean().item())\n",
    "    acc_std_by_step.append(accs.std().item())\n",
    "    print('step:', threshold.item(), 'acc:', accs.mean().item(), 'std:', accs.std().item())\n",
    "print(acc_mean_by_step, acc_std_by_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
