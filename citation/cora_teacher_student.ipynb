{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from model.layers import GraphSpectralFilterLayer, AnalysisFilter\n",
    "from model.spectral_filter import Graph\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from random import seed as rseed\n",
    "from numpy.random import seed as nseed\n",
    "from citation import get_dataset, random_planetoid_splits, run\n",
    "from citation.train_eval import evaluate\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'Cora'\n",
    "\n",
    "random_splits = False\n",
    "runs = 1\n",
    "alpha = 0.2\n",
    "seed =729\n",
    "weight_decay = 0.00012376256876336363\n",
    "patience=10\n",
    "hidden=32\n",
    "lr =0.001\n",
    "dropout=0.7\n",
    "heads =12\n",
    "output_heads =10\n",
    "normalize_features = True\n",
    "pre_training = False\n",
    "cuda = False\n",
    "chebyshev_order =16\n",
    "edge_dropout =0\n",
    "node_feature_dropout =0\n",
    "filter_name ='analysis'\n",
    "\n",
    "rseed(seed)\n",
    "nseed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "def get_correctly_predicted_node_idx(net, key, dataset):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        logits  = net(dataset[0])[0]\n",
    "    mask = dataset[0]['{}_mask'.format(key)]\n",
    "    pred = logits[mask].max(1)[1]\n",
    "    return { *pred.eq(dataset[0].y[mask]).nonzero().view(-1).tolist() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        data = dataset.data\n",
    "        adj = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.num_edges))\n",
    "        self.G = Graph(adj)\n",
    "        self.G.estimate_lmax()\n",
    "\n",
    "        self.analysis = GraphSpectralFilterLayer(self.G, dataset.num_node_features, hidden,\n",
    "                                                 dropout=dropout, out_channels=heads, filter=filter_name,\n",
    "                                                 pre_training=False, device='cuda' if cuda else 'cpu',\n",
    "                                                 alpha=alpha, chebyshev_order=chebyshev_order, concat=True)\n",
    "\n",
    "        self.synthesis = GraphSpectralFilterLayer(self.G, hidden * heads, dataset.num_classes, filter=filter_name,\n",
    "                                                  device='cuda' if cuda else 'cpu', dropout=dropout,\n",
    "                                                  out_channels=1, alpha=alpha, pre_training=False,\n",
    "                                                  chebyshev_order=chebyshev_order, concat=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.analysis.reset_parameters()\n",
    "        self.synthesis.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, att1 = self.analysis(x)\n",
    "        layer_1 = x\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, att2 = self.synthesis(x)\n",
    "        layer_2 = x\n",
    "        x = F.elu(x)\n",
    "        return F.log_softmax(x, dim=1), layer_1, layer_2\n",
    "\n",
    "dataset = get_dataset(dataset_name, normalize_features, edge_dropout=edge_dropout,\n",
    "                                node_feature_dropout=node_feature_dropout)\n",
    "\n",
    "if cuda:\n",
    "    dataset[0].to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.1689869910478592, 'train_acc': 0.9602649006622517, 'train_micro_f1': 0.9602649006622517, 'train_macro_f1': 0.9595082349503755, 'val_loss': 0.386290043592453, 'val_acc': 0.88, 'val_micro_f1': 0.88, 'val_macro_f1': 0.8731523860977931, 'test_loss': 0.39568036794662476, 'test_acc': 0.871, 'test_micro_f1': 0.871, 'test_macro_f1': 0.8612771708622864}\n"
     ]
    }
   ],
   "source": [
    "model = Net(dataset)\n",
    "model.load_state_dict(torch.load('./model/best_{}.pkl'.format(dataset_name),  map_location={'cuda:0': 'cpu'}))\n",
    "\n",
    "# model = SingleNet(dataset)\n",
    "# model.load_state_dict(torch.load('./model/best_{}_single_layer.pkl'.format(dataset_name)))\n",
    "\n",
    "# filter_kernel = model.analysis.filter_kernel\n",
    "\n",
    "# model_correct_indices = get_correctly_predicted_node_idx(model, 'test', dataset)\n",
    "eval_info = evaluate(model, dataset[0])\n",
    "print(eval_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "student_heads = 12\n",
    "hidden= 32\n",
    "dropout=0.4\n",
    "\n",
    "class StudentNet(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(StudentNet, self).__init__()\n",
    "        data = dataset.data\n",
    "        adj = torch.sparse_coo_tensor(data.edge_index, torch.ones(data.num_edges))\n",
    "        self.G = Graph(adj)\n",
    "        self.G.estimate_lmax()\n",
    "\n",
    "        self.analysis = GraphSpectralFilterLayer(self.G, dataset.num_node_features, hidden,\n",
    "                                                 dropout=dropout, out_channels=student_heads, filter=filter_name,\n",
    "                                                 pre_training=False, device='cuda' if cuda else 'cpu',\n",
    "                                                 alpha=alpha, chebyshev_order=chebyshev_order, concat=True)\n",
    "\n",
    "        self.synthesis = GraphSpectralFilterLayer(self.G, hidden * student_heads, dataset.num_classes, filter=filter_name,\n",
    "                                                  device='cuda' if cuda else 'cpu', dropout=dropout,\n",
    "                                                  out_channels=student_heads, alpha=alpha, pre_training=False,\n",
    "                                                  chebyshev_order=chebyshev_order, concat=False)\n",
    "    def reset_parameters(self):\n",
    "        self.analysis.reset_parameters()\n",
    "        self.synthesis.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, att1 = self.analysis(x)\n",
    "        layer_1 = x\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x, att2 = self.synthesis(x)\n",
    "        layer_2 = x\n",
    "        x = F.elu(x)\n",
    "        return F.log_softmax(x, dim=1), layer_1, layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_student(Model, target_1, target_2=None, lr=lr):\n",
    "    from torch.optim import Adam\n",
    "    from sklearn.metrics import f1_score\n",
    "    student = Model(dataset)\n",
    "    student.reset_parameters()\n",
    "    optimizer = Adam(student.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    data = dataset.data\n",
    "    epochs =2000\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        logits, out_2, out_1 = student(data)\n",
    "        loss = F.mse_loss(out_1[dataset[0].train_mask], target_1[dataset[0].train_mask])\n",
    "        if target_2 is not None:\n",
    "            loss += F.mse_loss(out_2[dataset[0].train_mask], target_2[dataset[0].train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        student.train()\n",
    "\n",
    "        # eval_info['epoch'] = epoch\n",
    "        if epoch % 10 == 0:\n",
    "            student.eval()\n",
    "            outs = {}\n",
    "            outs['loss'] = loss.item()\n",
    "            for key in ['train', 'val', 'test']:\n",
    "                mask = data['{}_mask'.format(key)]\n",
    "                loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
    "                pred = logits[mask].max(1)[1]\n",
    "\n",
    "                outs['{}_loss'.format(key)] = loss\n",
    "\n",
    "                outs['{}_micro_f1'.format(key)] = f1_score(data.y[mask].cpu(), logits[mask].max(1)[1].cpu(), average='micro')\n",
    "                outs['{}_macro_f1'.format(key)] = f1_score(data.y[mask].cpu(), logits[mask].max(1)[1].cpu(), average='macro')\n",
    "\n",
    "            print(outs)\n",
    "        # if eval_info['val_acc'] > best_val_acc or eval_info['val_loss'] < best_val_loss:\n",
    "        #     if eval_info['val_acc'] >= best_val_acc and eval_info['val_loss'] <= best_val_loss:\n",
    "        #         eval_info_early_model = eval_info\n",
    "        #         # torch.save(model.state_dict(), './best_{}_appnp.pkl'.format(dataset.name))\n",
    "        #     best_val_acc = np.max((best_val_acc, eval_info['val_acc']))\n",
    "        #     best_val_loss = np.min((best_val_loss, eval_info['val_loss']))\n",
    "        #     bad_counter = 0\n",
    "        # else:\n",
    "        #     bad_counter += 1\n",
    "        #     if bad_counter == patience:\n",
    "        #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.919919967651367, 'train_loss': 1.7399733066558838, 'train_micro_f1': 0.3029801324503311, 'train_macro_f1': 0.13771887088613244, 'val_loss': 1.727547287940979, 'val_micro_f1': 0.32, 'val_macro_f1': 0.13664554334615403, 'test_loss': 1.7215667963027954, 'test_micro_f1': 0.338, 'test_macro_f1': 0.15621878316250465}\n",
      "{'loss': 3.0983753204345703, 'train_loss': 1.420284628868103, 'train_micro_f1': 0.35513245033112584, 'train_macro_f1': 0.22148689214979386, 'val_loss': 1.424119472503662, 'val_micro_f1': 0.372, 'val_macro_f1': 0.19926486057613757, 'test_loss': 1.4157347679138184, 'test_micro_f1': 0.382, 'test_macro_f1': 0.2249923558005067}\n",
      "{'loss': 2.2616498470306396, 'train_loss': 1.049644947052002, 'train_micro_f1': 0.6539735099337748, 'train_macro_f1': 0.6072161378797253, 'val_loss': 1.0941120386123657, 'val_micro_f1': 0.626, 'val_macro_f1': 0.5615257773927025, 'test_loss': 1.0828052759170532, 'test_micro_f1': 0.639, 'test_macro_f1': 0.5807568224060097}\n",
      "{'loss': 1.5315266847610474, 'train_loss': 0.755852997303009, 'train_micro_f1': 0.7980132450331126, 'train_macro_f1': 0.7766403062560877, 'val_loss': 0.8232799768447876, 'val_micro_f1': 0.7699999999999999, 'val_macro_f1': 0.7464029439067624, 'test_loss': 0.7969115376472473, 'test_micro_f1': 0.778, 'test_macro_f1': 0.7536979442072013}\n",
      "{'loss': 1.021467685699463, 'train_loss': 0.5604063868522644, 'train_micro_f1': 0.8509933774834437, 'train_macro_f1': 0.8374480686958596, 'val_loss': 0.6540653705596924, 'val_micro_f1': 0.808, 'val_macro_f1': 0.7825454678152248, 'test_loss': 0.6388133764266968, 'test_micro_f1': 0.817, 'test_macro_f1': 0.8044454202440263}\n",
      "{'loss': 0.7121452689170837, 'train_loss': 0.4710943400859833, 'train_micro_f1': 0.8634105960264901, 'train_macro_f1': 0.8509865360164189, 'val_loss': 0.5771682858467102, 'val_micro_f1': 0.832, 'val_macro_f1': 0.8126355116625719, 'test_loss': 0.5439409613609314, 'test_micro_f1': 0.834, 'test_macro_f1': 0.8177251863374961}\n",
      "{'loss': 0.5489016175270081, 'train_loss': 0.39713433384895325, 'train_micro_f1': 0.8700331125827815, 'train_macro_f1': 0.8575204486854223, 'val_loss': 0.524523913860321, 'val_micro_f1': 0.8459999999999999, 'val_macro_f1': 0.8325054394227326, 'test_loss': 0.5146464109420776, 'test_micro_f1': 0.8289999999999998, 'test_macro_f1': 0.8178921049454095}\n",
      "{'loss': 0.48829782009124756, 'train_loss': 0.36899176239967346, 'train_micro_f1': 0.8832781456953642, 'train_macro_f1': 0.8747944906397047, 'val_loss': 0.48911574482917786, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8452400496849856, 'test_loss': 0.47252193093299866, 'test_micro_f1': 0.852, 'test_macro_f1': 0.8365037855557704}\n",
      "{'loss': 0.4719228446483612, 'train_loss': 0.3509938418865204, 'train_micro_f1': 0.8899006622516555, 'train_macro_f1': 0.8815177216210619, 'val_loss': 0.5206250548362732, 'val_micro_f1': 0.8399999999999999, 'val_macro_f1': 0.8242732272852918, 'test_loss': 0.478843629360199, 'test_micro_f1': 0.849, 'test_macro_f1': 0.8367404367965646}\n",
      "{'loss': 0.3901022672653198, 'train_loss': 0.33317726850509644, 'train_micro_f1': 0.8857615894039735, 'train_macro_f1': 0.8774019141526577, 'val_loss': 0.48073944449424744, 'val_micro_f1': 0.8599999999999999, 'val_macro_f1': 0.8523962724364147, 'test_loss': 0.46483758091926575, 'test_micro_f1': 0.853, 'test_macro_f1': 0.8450181254177345}\n",
      "{'loss': 0.35531818866729736, 'train_loss': 0.3198789954185486, 'train_micro_f1': 0.8981788079470199, 'train_macro_f1': 0.891520657035338, 'val_loss': 0.4507487416267395, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.853352840745657, 'test_loss': 0.45228782296180725, 'test_micro_f1': 0.857, 'test_macro_f1': 0.8459854362670363}\n",
      "{'loss': 0.34725043177604675, 'train_loss': 0.31689804792404175, 'train_micro_f1': 0.8965231788079471, 'train_macro_f1': 0.8904948812691484, 'val_loss': 0.46716755628585815, 'val_micro_f1': 0.854, 'val_macro_f1': 0.8495807873216256, 'test_loss': 0.4450076222419739, 'test_micro_f1': 0.859, 'test_macro_f1': 0.8497049878449869}\n",
      "{'loss': 0.3471955358982086, 'train_loss': 0.31616106629371643, 'train_micro_f1': 0.9006622516556292, 'train_macro_f1': 0.89553507200344, 'val_loss': 0.45413389801979065, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.8547434868911147, 'test_loss': 0.4455921947956085, 'test_micro_f1': 0.856, 'test_macro_f1': 0.8446513060922574}\n",
      "{'loss': 0.31857967376708984, 'train_loss': 0.3080042600631714, 'train_micro_f1': 0.9014900662251656, 'train_macro_f1': 0.8950990835520669, 'val_loss': 0.45845410227775574, 'val_micro_f1': 0.864, 'val_macro_f1': 0.8575135419445495, 'test_loss': 0.4599134922027588, 'test_micro_f1': 0.856, 'test_macro_f1': 0.8453254329597538}\n",
      "{'loss': 0.2909945547580719, 'train_loss': 0.28339001536369324, 'train_micro_f1': 0.9155629139072847, 'train_macro_f1': 0.9114357080423476, 'val_loss': 0.4419671893119812, 'val_micro_f1': 0.868, 'val_macro_f1': 0.8610247751593215, 'test_loss': 0.4438103139400482, 'test_micro_f1': 0.872, 'test_macro_f1': 0.8631404064158547}\n",
      "{'loss': 0.31043440103530884, 'train_loss': 0.29899826645851135, 'train_micro_f1': 0.9072847682119205, 'train_macro_f1': 0.9044359785326953, 'val_loss': 0.4556729793548584, 'val_micro_f1': 0.872, 'val_macro_f1': 0.8647586958016316, 'test_loss': 0.45441219210624695, 'test_micro_f1': 0.861, 'test_macro_f1': 0.8488105463139161}\n",
      "{'loss': 0.258266806602478, 'train_loss': 0.2848828434944153, 'train_micro_f1': 0.9172185430463576, 'train_macro_f1': 0.9134634502905075, 'val_loss': 0.4403211772441864, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.8570971089352567, 'test_loss': 0.45334509015083313, 'test_micro_f1': 0.856, 'test_macro_f1': 0.8463205328279569}\n",
      "{'loss': 0.28110530972480774, 'train_loss': 0.28038400411605835, 'train_micro_f1': 0.9155629139072847, 'train_macro_f1': 0.9119630843027663, 'val_loss': 0.43723413348197937, 'val_micro_f1': 0.864, 'val_macro_f1': 0.8597524831568073, 'test_loss': 0.44663122296333313, 'test_micro_f1': 0.8619999999999999, 'test_macro_f1': 0.848913506440506}\n",
      "{'loss': 0.27968961000442505, 'train_loss': 0.27880892157554626, 'train_micro_f1': 0.9213576158940397, 'train_macro_f1': 0.9207965455886037, 'val_loss': 0.45190903544425964, 'val_micro_f1': 0.866, 'val_macro_f1': 0.8561102616705526, 'test_loss': 0.4416288435459137, 'test_micro_f1': 0.868, 'test_macro_f1': 0.8574170466202488}\n",
      "{'loss': 0.25219297409057617, 'train_loss': 0.28306376934051514, 'train_micro_f1': 0.9114238410596026, 'train_macro_f1': 0.9043331201544719, 'val_loss': 0.4707302153110504, 'val_micro_f1': 0.838, 'val_macro_f1': 0.8330892780546983, 'test_loss': 0.4492918848991394, 'test_micro_f1': 0.855, 'test_macro_f1': 0.844455008749528}\n",
      "{'loss': 0.26489487290382385, 'train_loss': 0.27982813119888306, 'train_micro_f1': 0.9205298013245033, 'train_macro_f1': 0.9180368663002437, 'val_loss': 0.43788963556289673, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8525891831246579, 'test_loss': 0.4564889967441559, 'test_micro_f1': 0.85, 'test_macro_f1': 0.835627649249606}\n",
      "{'loss': 0.2624608278274536, 'train_loss': 0.27304431796073914, 'train_micro_f1': 0.918046357615894, 'train_macro_f1': 0.9132752459974892, 'val_loss': 0.45362144708633423, 'val_micro_f1': 0.866, 'val_macro_f1': 0.8615067661035466, 'test_loss': 0.4463197886943817, 'test_micro_f1': 0.861, 'test_macro_f1': 0.8483413763398989}\n",
      "{'loss': 0.2502739727497101, 'train_loss': 0.2652708888053894, 'train_micro_f1': 0.9213576158940397, 'train_macro_f1': 0.9181642363166702, 'val_loss': 0.4549615979194641, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8520062637044915, 'test_loss': 0.46502885222435, 'test_micro_f1': 0.854, 'test_macro_f1': 0.8423948519784289}\n",
      "{'loss': 0.2494347244501114, 'train_loss': 0.2695387303829193, 'train_micro_f1': 0.9238410596026491, 'train_macro_f1': 0.9202049362807756, 'val_loss': 0.430964857339859, 'val_micro_f1': 0.8599999999999999, 'val_macro_f1': 0.8483477918583157, 'test_loss': 0.4475782513618469, 'test_micro_f1': 0.859, 'test_macro_f1': 0.8473734606055379}\n",
      "{'loss': 0.27455824613571167, 'train_loss': 0.2705692648887634, 'train_micro_f1': 0.9130794701986755, 'train_macro_f1': 0.9103742560941345, 'val_loss': 0.4370359778404236, 'val_micro_f1': 0.872, 'val_macro_f1': 0.8694501723695004, 'test_loss': 0.44180750846862793, 'test_micro_f1': 0.864, 'test_macro_f1': 0.854713731101121}\n",
      "{'loss': 0.24960355460643768, 'train_loss': 0.2614894509315491, 'train_micro_f1': 0.9221854304635762, 'train_macro_f1': 0.9191406910244719, 'val_loss': 0.424850195646286, 'val_micro_f1': 0.88, 'val_macro_f1': 0.8736166612667391, 'test_loss': 0.44215109944343567, 'test_micro_f1': 0.859, 'test_macro_f1': 0.8470160749683828}\n",
      "{'loss': 0.2259332537651062, 'train_loss': 0.26382240653038025, 'train_micro_f1': 0.9221854304635762, 'train_macro_f1': 0.9182270921025911, 'val_loss': 0.4374171197414398, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8501666245472793, 'test_loss': 0.43725281953811646, 'test_micro_f1': 0.864, 'test_macro_f1': 0.8540383983033841}\n",
      "{'loss': 0.22858551144599915, 'train_loss': 0.27032554149627686, 'train_micro_f1': 0.9230132450331126, 'train_macro_f1': 0.9197945950728753, 'val_loss': 0.4638727903366089, 'val_micro_f1': 0.85, 'val_macro_f1': 0.8482385622602838, 'test_loss': 0.4458180367946625, 'test_micro_f1': 0.866, 'test_macro_f1': 0.8573396986984434}\n",
      "{'loss': 0.22111836075782776, 'train_loss': 0.24574697017669678, 'train_micro_f1': 0.9230132450331126, 'train_macro_f1': 0.9182071652242472, 'val_loss': 0.4493688642978668, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.8547900089583297, 'test_loss': 0.4642693102359772, 'test_micro_f1': 0.852, 'test_macro_f1': 0.8413759805993004}\n",
      "{'loss': 0.236507847905159, 'train_loss': 0.2716725468635559, 'train_micro_f1': 0.9172185430463576, 'train_macro_f1': 0.9122207076626967, 'val_loss': 0.450090616941452, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.8558337611966962, 'test_loss': 0.4472205936908722, 'test_micro_f1': 0.866, 'test_macro_f1': 0.8546587982402054}\n",
      "{'loss': 0.21064254641532898, 'train_loss': 0.25734764337539673, 'train_micro_f1': 0.9221854304635762, 'train_macro_f1': 0.9174790152603816, 'val_loss': 0.4459781050682068, 'val_micro_f1': 0.864, 'val_macro_f1': 0.8564506358558502, 'test_loss': 0.4500948488712311, 'test_micro_f1': 0.857, 'test_macro_f1': 0.849279419344157}\n",
      "{'loss': 0.2031272053718567, 'train_loss': 0.26473426818847656, 'train_micro_f1': 0.9197019867549668, 'train_macro_f1': 0.9168548937591626, 'val_loss': 0.46570879220962524, 'val_micro_f1': 0.848, 'val_macro_f1': 0.8387100883783767, 'test_loss': 0.46213674545288086, 'test_micro_f1': 0.8619999999999999, 'test_macro_f1': 0.8526533528212397}\n",
      "{'loss': 0.2053680568933487, 'train_loss': 0.26413288712501526, 'train_micro_f1': 0.9213576158940397, 'train_macro_f1': 0.9174958445808601, 'val_loss': 0.4478032886981964, 'val_micro_f1': 0.8599999999999999, 'val_macro_f1': 0.8534440244119538, 'test_loss': 0.4669366776943207, 'test_micro_f1': 0.85, 'test_macro_f1': 0.8398992137396764}\n",
      "{'loss': 0.22622832655906677, 'train_loss': 0.2650407552719116, 'train_micro_f1': 0.9155629139072847, 'train_macro_f1': 0.9088158087531318, 'val_loss': 0.44569507241249084, 'val_micro_f1': 0.85, 'val_macro_f1': 0.8459965103588608, 'test_loss': 0.4379219710826874, 'test_micro_f1': 0.869, 'test_macro_f1': 0.8549381026593036}\n",
      "{'loss': 0.24316801130771637, 'train_loss': 0.2594905495643616, 'train_micro_f1': 0.9246688741721856, 'train_macro_f1': 0.9214280908910064, 'val_loss': 0.4606640338897705, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.8556185599670928, 'test_loss': 0.458330363035202, 'test_micro_f1': 0.8599999999999999, 'test_macro_f1': 0.8494519147151209}\n",
      "{'loss': 0.21620231866836548, 'train_loss': 0.2664593756198883, 'train_micro_f1': 0.9238410596026491, 'train_macro_f1': 0.9193626365132934, 'val_loss': 0.46064192056655884, 'val_micro_f1': 0.8459999999999999, 'val_macro_f1': 0.8348780212411081, 'test_loss': 0.46341416239738464, 'test_micro_f1': 0.8599999999999999, 'test_macro_f1': 0.8513446833641213}\n",
      "{'loss': 0.20570406317710876, 'train_loss': 0.25739461183547974, 'train_micro_f1': 0.9221854304635762, 'train_macro_f1': 0.9170406655120559, 'val_loss': 0.42095786333084106, 'val_micro_f1': 0.864, 'val_macro_f1': 0.8604372927624828, 'test_loss': 0.4510861039161682, 'test_micro_f1': 0.8599999999999999, 'test_macro_f1': 0.8454172478976119}\n",
      "{'loss': 0.20197062194347382, 'train_loss': 0.256745308637619, 'train_micro_f1': 0.9238410596026491, 'train_macro_f1': 0.920698475690114, 'val_loss': 0.4561678171157837, 'val_micro_f1': 0.848, 'val_macro_f1': 0.8418330590657764, 'test_loss': 0.44715967774391174, 'test_micro_f1': 0.859, 'test_macro_f1': 0.8495837153879845}\n",
      "{'loss': 0.22840556502342224, 'train_loss': 0.2641191780567169, 'train_micro_f1': 0.9221854304635762, 'train_macro_f1': 0.9175240309916752, 'val_loss': 0.4404337406158447, 'val_micro_f1': 0.868, 'val_macro_f1': 0.8642848531492842, 'test_loss': 0.44128283858299255, 'test_micro_f1': 0.857, 'test_macro_f1': 0.846929080550323}\n",
      "{'loss': 0.21059668064117432, 'train_loss': 0.2504064440727234, 'train_micro_f1': 0.9221854304635762, 'train_macro_f1': 0.9182639137937343, 'val_loss': 0.43008357286453247, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8459744818042448, 'test_loss': 0.45167413353919983, 'test_micro_f1': 0.855, 'test_macro_f1': 0.842617809243529}\n",
      "{'loss': 0.19908441603183746, 'train_loss': 0.2573309540748596, 'train_micro_f1': 0.9213576158940397, 'train_macro_f1': 0.919091324640778, 'val_loss': 0.447830468416214, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8463162673497703, 'test_loss': 0.45885902643203735, 'test_micro_f1': 0.854, 'test_macro_f1': 0.8417553609257754}\n",
      "{'loss': 0.20541763305664062, 'train_loss': 0.25732746720314026, 'train_micro_f1': 0.9213576158940397, 'train_macro_f1': 0.9198075233675439, 'val_loss': 0.4298263192176819, 'val_micro_f1': 0.8619999999999999, 'val_macro_f1': 0.8561797398855562, 'test_loss': 0.4683043360710144, 'test_micro_f1': 0.853, 'test_macro_f1': 0.8417991623736568}\n",
      "{'loss': 0.18957403302192688, 'train_loss': 0.25119733810424805, 'train_micro_f1': 0.9279801324503312, 'train_macro_f1': 0.9262386365221875, 'val_loss': 0.46050846576690674, 'val_micro_f1': 0.842, 'val_macro_f1': 0.8337507193143268, 'test_loss': 0.44300106167793274, 'test_micro_f1': 0.859, 'test_macro_f1': 0.8475428227368287}\n",
      "{'loss': 0.1989058256149292, 'train_loss': 0.2495241016149521, 'train_micro_f1': 0.9263245033112583, 'train_macro_f1': 0.9225684472786059, 'val_loss': 0.4389040470123291, 'val_micro_f1': 0.856, 'val_macro_f1': 0.8432431499623313, 'test_loss': 0.4674169719219208, 'test_micro_f1': 0.853, 'test_macro_f1': 0.8385664461668377}\n",
      "{'loss': 0.2123723179101944, 'train_loss': 0.2545183598995209, 'train_micro_f1': 0.9205298013245033, 'train_macro_f1': 0.9168702014529799, 'val_loss': 0.45631173253059387, 'val_micro_f1': 0.848, 'val_macro_f1': 0.8418168328206896, 'test_loss': 0.4561401605606079, 'test_micro_f1': 0.851, 'test_macro_f1': 0.8397388806132563}\n",
      "{'loss': 0.20105063915252686, 'train_loss': 0.258815199136734, 'train_micro_f1': 0.918046357615894, 'train_macro_f1': 0.9165663399489031, 'val_loss': 0.44100093841552734, 'val_micro_f1': 0.858, 'val_macro_f1': 0.8475341417758984, 'test_loss': 0.4597724676132202, 'test_micro_f1': 0.85, 'test_macro_f1': 0.8399971842415849}\n",
      "{'loss': 0.20739072561264038, 'train_loss': 0.24992813169956207, 'train_micro_f1': 0.9254966887417219, 'train_macro_f1': 0.9207335915621212, 'val_loss': 0.44276195764541626, 'val_micro_f1': 0.854, 'val_macro_f1': 0.8468226981968641, 'test_loss': 0.45187872648239136, 'test_micro_f1': 0.858, 'test_macro_f1': 0.8473249803855583}\n",
      "{'loss': 0.21055768430233002, 'train_loss': 0.2554861903190613, 'train_micro_f1': 0.9246688741721856, 'train_macro_f1': 0.9231915993766816, 'val_loss': 0.4418680667877197, 'val_micro_f1': 0.866, 'val_macro_f1': 0.8618435742845217, 'test_loss': 0.4609891176223755, 'test_micro_f1': 0.847, 'test_macro_f1': 0.8367249178867364}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    _, target_1, target_2 = model(dataset[0])\n",
    "\n",
    "train_student(StudentNet, target_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(\n",
    "            dataset.num_features,\n",
    "            8,\n",
    "            heads=8,\n",
    "            dropout=0.6)\n",
    "        self.conv2 = GATConv(\n",
    "            64,\n",
    "            dataset.num_classes,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=0.6)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x, (edge_index_1, att_val_1) = self.conv1(x, edge_index, return_attention_weights=True)\n",
    "        layer_1 = x\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x, (edge_index_2, att_val_2) = self.conv2(x, edge_index, return_attention_weights=True)\n",
    "        layer_2 = x\n",
    "        return F.log_softmax(x, dim=1), layer_1, layer_2\n",
    "\n",
    "gat = GAT(dataset)\n",
    "gat.load_state_dict(torch.load('./model/best_{}_public_gat.pkl'.format(dataset_name)))\n",
    "evaluate(gat, dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _, gat_target_1, gat_target_2 = gat(dataset[0])\n",
    "\n",
    "train_student(StudentNet, gat_target_2, gat_target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, out_channel):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.out_channel = out_channel\n",
    "#         self.layers = nn.Sequential(nn.Linear(dataset.num_node_features, 128),\n",
    "#                                     nn.ReLU(inplace=True),\n",
    "#                                     nn.Linear(128, 64),\n",
    "#                                     nn.ReLU(inplace=True),\n",
    "#                                     nn.Linear(64, 32),\n",
    "#                                     nn.ReLU(inplace=True),\n",
    "#                                     nn.Linear(32, dataset.num_classes),\n",
    "#                                     nn.ReLU(inplace=True))\n",
    "#\n",
    "#     def reset_parameters(self):\n",
    "#         for layer in self.layers:\n",
    "#             if hasattr(layer, 'reset_parameters'):\n",
    "#                 layer.reset_parameters()\n",
    "#\n",
    "#     def forward(self, data):\n",
    "#         x = self.layers(data.x)\n",
    "#         return F.log_softmax(x, dim=1), x, None\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_student(MLP, gat_soft_target)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import SGConv\n",
    "#\n",
    "# class SGC(torch.nn.Module):\n",
    "#     def __init__(self, dataset):\n",
    "#         super(SGC, self).__init__()\n",
    "#         self.conv1 = SGConv(\n",
    "#             dataset.num_features, dataset.num_classes, K=2, cached=True)\n",
    "#\n",
    "#     def reset_parameters(self):\n",
    "#         self.conv1.reset_parameters()\n",
    "#\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         return F.log_softmax(x, dim=1), x\n",
    "#\n",
    "# dataset_unnormalized = get_dataset(dataset_name, False, edge_dropout=edge_dropout,\n",
    "#                                 node_feature_dropout=node_feature_dropout)\n",
    "# sgc = SGC(dataset_unnormalized)\n",
    "# sgc.load_state_dict(torch.load('./model/best_{}_sgc.pkl'.format(dataset_name)))\n",
    "# print(evaluate(sgc, dataset_unnormalized[0]))\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     sgc_soft_target = sgc(dataset_unnormalized[0])[1]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_student(StudentNet, sgc_soft_target)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (decimation_branch_mark)",
   "language": "python",
   "name": "pycharm-daac98f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}